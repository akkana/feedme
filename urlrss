#!/usr/bin/env python

# Make a local RSS file based on a list of URLs,
# so we can run feedme to collect those URLs.
# Can be run locally as a script, or can be installed on a web server
# as a CGI (see feedfetcher for details on how to set that up).
#
# The URLs may be passed in as a POST query, if running as a CGI;
# or if there's no query string (we're running it locally as a script),
# we'll try to mount the Android device # and collect URLs from a file
# there and from another one locally.

import os, sys
import time, datetime
import subprocess
import urllib2
import xml.sax.saxutils

import cgi

##############################
# CONFIGURATION
##############################
# Path to mount the device:
if len(sys.argv) > 1 :
    devicepath = sys.argv[1]
else :
    devicepath = "/droidsd"

# Where to look for the saved URL files.
# This will be tilde-expanded after we've ascertained whether
# we're running from a CGI.
urlfiles = [ "~/feeds/localurls" ]

# Where to create the RSS file.
# Will be tilde-expanded.
rssfile = "~/feeds/xtraurls.rss"

# Where to save an HTML-format archive of the URLs.
# We'll append to what's already there.
urlarchive = "~/.cache/feedme/xtraurls.html"

# The home dir of the server -- under which we should find feeds and feedme.
#serverhome = '/var/www'
serverhome = '/public/shallowsky/'

# The path to feedme on the web server, as seen from the www-data user.
# If you've set serverhome you can probably leave this alone.
feedme_exec = serverhome + 'feedme/feedme'

# Optional: a file path on the server to log output to.
# This will only be used in CGI mode.
# Set to None for no debugging.
# If you've set serverhome you can probably leave this alone.
debuglog = serverhome + 'feeds/log-urlrss'

##############################
# END CONFIGURATION
# (Shouldn't need to change anything below this)
##############################

urls = []

# We need to be able to handle either text or HTML output:
html_output = False
line_sep = ''

# See if we're being called as a CGI script:
form = cgi.FieldStorage()
if 'xtraurls' in form:
    html_output = True
    if debuglog:
        debuglog = open(debuglog, 'w')
    formurls = form['xtraurls'].value.strip().split('\n')
    for url in formurls:
        # We have to pass xtraurls=none in the case of no URLs,
        # otherwise 'xtraurls' in form tests False and we have
        # no way of knowing we're being run from a CGI.
        if url != 'none':
            urls.append(url)

    html_output = True

    # Don't want to rely on config/cache files in the homedir of
    # whatever user might be running the web server.
    # Instead, try to force HOME:
    os.environ['HOME'] = serverhome + 'feedme'

    # Tilde-expand our various configuration variables,
    # now that we know HOME is set appropriately.
    urlfiles = map(os.path.expanduser, urlfiles)
    rssfile = os.path.expanduser(rssfile)
    urlarchive = os.path.expanduser(urlarchive)

    if debuglog:
        # and redirect stderr to there:
        sys.stderr = debuglog

        print >>debuglog, "devicepath:", devicepath
        print >>debuglog, "urlfiles:", urlfiles
        print >>debuglog, "rssfile:", rssfile
        print >>debuglog, "urlarchive:", urlarchive
        print >>debuglog, "feedme exec:", feedme_exec
        print >>debuglog, 'HOME:', os.environ['HOME']

    line_sep = '<br>'
    print '''Content-type: text/html

<html>
<head>
<title>Extra URLs</title>
</head>

<body>

<h1>Extra URLs</h1>

<p>'''

else:
    # Mount the device's SD card if it isn't already mounted:
    if not os.path.ismount(devicepath) :
        subprocess.call(["mount", devicepath])
        # Ignore return value: it will be nonzero if already mounted.
        # So check to see if it's mounted now:
        if not os.path.ismount(devicepath) :
            print "Can't mount %s!" % devicepath
            sys.exit(1)
    else: print "Device is already mounted."
    urlfiles.append(os.path.join(devicepath, "feeds", "saved-urls"))

# Loop over all the url files to get our list of urls:
for urlfile in urlfiles :
    try :
        ifp = open(urlfile)
        print >>sys.stderr, "Reading URLs from", urlfile, line_sep
    except :
        continue

    for line in ifp :
        line = line.strip()
        if not line : continue
        urls.append(line)

    ifp.close()
    os.unlink(urlfile)

if not urls :
    print >>sys.stderr, "No saved URLs", line_sep
    if os.path.exists(rssfile) :
        os.unlink(rssfile)

else:
    #
    # We have URLs to save. So open the output files.
    #

    try :
        ofp = open(rssfile, "w")
    except :
        print >>sys.stderr, "Couldn't write to RSS file", rssfile, line_sep
        sys.exit(1)

    print >>ofp, """<rss version="0.91">
<channel>
  <title>FeedMe URLs</title>
  <description>Saved URLs %s</description>
  <language>en</language>""" % datetime.datetime.now().ctime()

    try :
        archivefp = open(urlarchive, "a")
        print >>archivefp, "\n<h4>Feedme URLs %s</h4>" \
            % datetime.datetime.now().ctime()
    except :
        print >>sys.stderr, "Couldn't open archive file", urlarchive, line_sep
        archivefp = None

    for url in urls :
        # Follow it and see if it's a redirect -- we want the real, final url.
        try :
            print >>sys.stderr, url, "...",
            sys.stdout.flush()
            urlobj = urllib2.urlopen(url, timeout=60)
            newurl = urlobj.geturl()
            urlobj.close()
            if newurl != url :
                print >>sys.stderr, "redirected to", newurl, line_sep
                url = newurl
            else :
                print  >>sys.stderr,".", line_sep
        except :
            pass

        # The XML parser we use in feedme will sometimes barf on ampersands:
        # "xml.sax._exceptions.SAXException: Read failed (no details available)"
        # and not even a stack trace to give a line number.
        # Try to avoid that by escaping everything (and hope that
        # doesn't break link following):
        escaped_url = xml.sax.saxutils.escape(url)

        # Save it in the RSS file:
        print >>ofp, """
<item>
  <title>%s</title>
  <description>%s</description>
  <link>%s</link>
</item>""" % (escaped_url, escaped_url, escaped_url)

        # Save an HTML copy to the archive file:
        if archivefp :
            print >>archivefp, "<a href='%s'>%s</a>" % (url, url)

    print >>ofp, """</channel>
</rss>"""

    ofp.close()
    if archivefp :
        archivefp.close()

    if urls :
        print >>sys.stderr, "Saved %s urls to %s and %s" % (len(urls),
                                                            rssfile, urlarchive)

# Done making the Xtra RSS file (if any).

if html_output :
    # If we're being run as a CGI, it's because someone wants us
    # to kick off a feedme process. So do so:
    # Don't need to pass env= in the next call,
    # because changing os.environ earlier already changed the environment
    # that will be passed through to subprocesses.

    # We need to throw away feedme's output (but it should be captured
    # in feedme's log file anyway) otherwise the web server won't
    # deliver any page content until feedme is completely done
    # (or it times out).
    devnull = open(os.devnull, 'wb')

    # Start feedme running in the background, so we can return immediately.
    print >>sys.stderr, "<p>Trying to run %s ..." % feedme_exec
    subprocess.Popen([feedme_exec],
                     stdout=devnull, stderr=devnull)
    print >>sys.stderr, "<p>Feedme should be running now."

    print '''</ul>
</body>
</html>'''

